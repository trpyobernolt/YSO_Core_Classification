{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4db07fbe",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'DecisionBoundaryDisplay' from 'sklearn.inspection' (/home/quang/.local/lib/python3.9/site-packages/sklearn/inspection/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-7cfb09a28470>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnaive_bayes\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGaussianNB\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiscriminant_analysis\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mQuadraticDiscriminantAnalysis\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minspection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDecisionBoundaryDisplay\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'DecisionBoundaryDisplay' from 'sklearn.inspection' (/home/quang/.local/lib/python3.9/site-packages/sklearn/inspection/__init__.py)"
     ]
    }
   ],
   "source": [
    "## for data\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "## for plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "## for statistical tests\n",
    "import scipy\n",
    "#import statsmodels.formula.api as smf\n",
    "#import statsmodels.api as sm\n",
    "\n",
    "## for machine learning\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import model_selection, preprocessing, feature_selection, ensemble, linear_model, metrics, decomposition\n",
    "\n",
    "# Import Gaussian Naive Bayes classifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# Import Evaluation Metric\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "## for explainer\n",
    "#from lime import lime_tabular\n",
    "\n",
    "\n",
    "#!pip3 install pandas\n",
    "\n",
    "\n",
    "#https://towardsdatascience.com/machine-learning-with-python-classification-complete-tutorial-d2c99dc524ec\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler \n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "import pandas as pd \n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import make_moons, make_circles, make_classification\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.inspection import DecisionBoundaryDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9c8d2a7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['sepal.length', 'sepal.width', 'petal.length', 'petal.width',\n",
      "       'variety'],\n",
      "      dtype='object')\n",
      "     sepal.length  sepal.width  petal.length  petal.width    variety\n",
      "0             5.1          3.5           1.4          0.2     Setosa\n",
      "1             4.9          3.0           1.4          0.2     Setosa\n",
      "2             4.7          3.2           1.3          0.2     Setosa\n",
      "3             4.6          3.1           1.5          0.2     Setosa\n",
      "4             5.0          3.6           1.4          0.2     Setosa\n",
      "..            ...          ...           ...          ...        ...\n",
      "145           6.7          3.0           5.2          2.3  Virginica\n",
      "146           6.3          2.5           5.0          1.9  Virginica\n",
      "147           6.5          3.0           5.2          2.0  Virginica\n",
      "148           6.2          3.4           5.4          2.3  Virginica\n",
      "149           5.9          3.0           5.1          1.8  Virginica\n",
      "\n",
      "[150 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "## for data\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "# LOAD DATA \n",
    "# Convert dataset to a pandas dataframe:\n",
    "dataset = pd.read_csv('iris.csv') \n",
    "print(dataset.columns)\n",
    "print(dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b7690a55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['sepal.length', 'sepal.width', 'petal.length', 'petal.width',\n",
      "       'variety'],\n",
      "      dtype='object')\n",
      "   sepal.length  sepal.width  petal.length  petal.width variety\n",
      "0           5.1          3.5           1.4          0.2  Setosa\n",
      "1           4.9          3.0           1.4          0.2  Setosa\n",
      "2           4.7          3.2           1.3          0.2  Setosa\n",
      "3           4.6          3.1           1.5          0.2  Setosa\n",
      "4           5.0          3.6           1.4          0.2  Setosa\n",
      "Summary Statistics of the X dataframe \n",
      "        sepal.length  sepal.width  petal.length  petal.width\n",
      "count    150.000000   150.000000    150.000000   150.000000\n",
      "mean       5.843333     3.057333      3.758000     1.199333\n",
      "std        0.828066     0.435866      1.765298     0.762238\n",
      "min        4.300000     2.000000      1.000000     0.100000\n",
      "25%        5.100000     2.800000      1.600000     0.300000\n",
      "50%        5.800000     3.000000      4.350000     1.300000\n",
      "75%        6.400000     3.300000      5.100000     1.800000\n",
      "max        7.900000     4.400000      6.900000     2.500000\n",
      "(150, 4) (150,)\n",
      "(105, 4) (105,)\n",
      "(45, 4) (45,)\n",
      "\n",
      " Summary Statistics of the X dataframe after Standard Scaling\n",
      "                   0             1             2             3\n",
      "count  1.050000e+02  1.050000e+02  1.050000e+02  1.050000e+02\n",
      "mean   4.736952e-16 -3.801192e-16  1.543739e-16  1.374562e-16\n",
      "std    1.004796e+00  1.004796e+00  1.004796e+00  1.004796e+00\n",
      "min   -1.865822e+00 -2.328273e+00 -1.559301e+00 -1.440246e+00\n",
      "25%   -8.757458e-01 -5.224103e-01 -1.216538e+00 -1.170921e+00\n",
      "50%   -9.429295e-03 -7.094461e-02  2.687700e-01  1.757023e-01\n",
      "75%    6.093682e-01  6.062540e-01  7.257878e-01  8.490138e-01\n",
      "max    2.342001e+00  2.637850e+00  1.811205e+00  1.791650e+00\n",
      "\n",
      " Summary Statistics of the X dataframe after MinMaxScaler Scaling\n",
      "                 0           1           2           3\n",
      "count  105.000000  105.000000  105.000000  105.000000\n",
      "mean     0.443417    0.468831    0.462631    0.445635\n",
      "std      0.238792    0.202330    0.298114    0.310900\n",
      "min      0.000000    0.000000    0.000000    0.000000\n",
      "25%      0.235294    0.363636    0.101695    0.083333\n",
      "50%      0.441176    0.454545    0.542373    0.500000\n",
      "75%      0.588235    0.590909    0.677966    0.708333\n",
      "max      1.000000    1.000000    1.000000    1.000000\n",
      "[[15  0  0]\n",
      " [ 0 12  1]\n",
      " [ 0  0 17]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Setosa       1.00      1.00      1.00        15\n",
      "  Versicolor       1.00      0.92      0.96        13\n",
      "   Virginica       0.94      1.00      0.97        17\n",
      "\n",
      "    accuracy                           0.98        45\n",
      "   macro avg       0.98      0.97      0.98        45\n",
      "weighted avg       0.98      0.98      0.98        45\n",
      "\n",
      "0.9777777777777777\n",
      "26         Setosa\n",
      "142     Virginica\n",
      "55     Versicolor\n",
      "76     Versicolor\n",
      "140     Virginica\n",
      "11         Setosa\n",
      "57     Versicolor\n",
      "3          Setosa\n",
      "51     Versicolor\n",
      "75     Versicolor\n",
      "145     Virginica\n",
      "47         Setosa\n",
      "27         Setosa\n",
      "21         Setosa\n",
      "147     Virginica\n",
      "36         Setosa\n",
      "80     Versicolor\n",
      "115     Virginica\n",
      "77     Versicolor\n",
      "38         Setosa\n",
      "5          Setosa\n",
      "123     Virginica\n",
      "86     Versicolor\n",
      "95     Versicolor\n",
      "40         Setosa\n",
      "111     Virginica\n",
      "112     Virginica\n",
      "109     Virginica\n",
      "88     Versicolor\n",
      "104     Virginica\n",
      "103     Virginica\n",
      "68     Versicolor\n",
      "6          Setosa\n",
      "15         Setosa\n",
      "139     Virginica\n",
      "69     Versicolor\n",
      "28         Setosa\n",
      "124     Virginica\n",
      "131     Virginica\n",
      "128     Virginica\n",
      "12         Setosa\n",
      "149     Virginica\n",
      "49         Setosa\n",
      "56     Versicolor\n",
      "135     Virginica\n",
      "Name: variety, dtype: object ['Setosa' 'Virginica' 'Versicolor' 'Versicolor' 'Virginica' 'Setosa'\n",
      " 'Versicolor' 'Setosa' 'Versicolor' 'Versicolor' 'Virginica' 'Setosa'\n",
      " 'Setosa' 'Setosa' 'Virginica' 'Setosa' 'Versicolor' 'Virginica'\n",
      " 'Versicolor' 'Setosa' 'Setosa' 'Virginica' 'Versicolor' 'Versicolor'\n",
      " 'Setosa' 'Virginica' 'Virginica' 'Virginica' 'Versicolor' 'Virginica'\n",
      " 'Virginica' 'Virginica' 'Setosa' 'Setosa' 'Virginica' 'Versicolor'\n",
      " 'Setosa' 'Virginica' 'Virginica' 'Virginica' 'Setosa' 'Virginica'\n",
      " 'Setosa' 'Versicolor' 'Virginica']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# TASK: LOAD DATA THAT WAS GIVEN TO YOU\n",
    "# Convert dataset to a pandas dataframe\n",
    "dataset = pd.read_csv('iris.csv') \n",
    "print(dataset.columns)\n",
    "\n",
    "# TASK: INSPECT DATA\n",
    "# Plot histogram,boxplots, heatmap\n",
    "# Check variable stasttics\n",
    "# Check NaN values, etc.\n",
    "# Visualize correlation\n",
    "\n",
    "\n",
    "# TASK: DATA ENGINEERING, FEATURE ENGINEERING\n",
    "# Use head() function to return the first 5 rows: \n",
    "print(dataset.head()) \n",
    "# Assign values to the X and y variables:\n",
    "X = dataset.iloc[:, :-1].values\n",
    "y = dataset.iloc[:, 4].values \n",
    "X = dataset[['sepal.length', 'sepal.width', 'petal.length', 'petal.width']]\n",
    "y = dataset['variety']\n",
    "\n",
    "print(\"Summary Statistics of the X dataframe \\n\", X.describe())\n",
    "\n",
    "# Split dataset into random train and test subsets:\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30) \n",
    "\n",
    "\n",
    "print(X.shape, y.shape)\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)\n",
    "\n",
    "# Standardizing variable\n",
    "#Instruction: This step is optional\n",
    "# You can use non, one or all of these scalers to find better model, \n",
    "# i.e. models with better accuracy & precision.\n",
    "# For other scaling or feature engineering methods, check this ref:\n",
    "# https://scikit-learn.org/stable/modules/classes.html?highlight=sklearn+preprocessing#module-sklearn.preprocessing\n",
    "\n",
    "# Standardize features by removing mean and scaling to unit variance:\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test) \n",
    "\n",
    "X_train_df = pd.DataFrame(X_train)\n",
    "print(\"\\n Summary Statistics of the X dataframe after Standard Scaling\\n\", X_train_df.describe())\n",
    "\n",
    "# MinmaxScaling features by removing mean and scaling to unit variance:\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test) \n",
    "\n",
    "X_train_df = pd.DataFrame(X_train)\n",
    "print(\"\\n Summary Statistics of the X dataframe after MinMaxScaler Scaling\\n\", X_train_df.describe())\n",
    "\n",
    "\n",
    "\n",
    "# SELECT MODEL\n",
    "#classifiers = [\n",
    "#    KNeighborsClassifier(n_neighbors=3),\n",
    "#    DecisionTreeClassifier(max_depth=5),\n",
    "#    SVC(kernel=\"linear\", C=0.025),\n",
    "#    SVC(gamma=2, C=1),\n",
    "#    GaussianProcessClassifier(1.0 * RBF(1.0)),\n",
    "#    RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1),\n",
    "#    MLPClassifier(alpha=1, max_iter=1000),\n",
    "#    AdaBoostClassifier(),\n",
    "#    GaussianNB(),\n",
    "#    QuadraticDiscriminantAnalysis(),\n",
    "#]\n",
    "\n",
    "# TASK:\n",
    "# Initialize classifier\n",
    "# Choose 3 classifers\n",
    "# Check the paramters of these classifiers using sklearn manuals\n",
    "# Change the paramters manualy or by using for loop to choose the better model (model with better metrics)\n",
    "\n",
    "\n",
    "# Use the KNN classifier to fit data:\n",
    "classifier = KNeighborsClassifier(n_neighbors=3)  \n",
    "\n",
    "# Gaussian Process Classifier\n",
    "classifier = DecisionTreeClassifier(max_depth=5)  \n",
    "\n",
    "# Support Vector Machine\n",
    "classifier = SVC(kernel=\"linear\", C=0.025)\n",
    "\n",
    "# Support Vector Machine\n",
    "classifier = SVC(gamma=2, C=1)  \n",
    "\n",
    "# Gaussian Process Classifier\n",
    "classifier = GaussianProcessClassifier(1.0 * RBF(1.0)) \n",
    "\n",
    "# RandomForestClassifier\n",
    "classifier = RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1)\n",
    "\n",
    "# MLPClassifier\n",
    "classifier = MLPClassifier(alpha=1, max_iter=1000)\n",
    "\n",
    "# AdaBoostClassifier\n",
    "classifier = AdaBoostClassifier()\n",
    "\n",
    "# GnB\n",
    "classifier = GaussianNB()  \n",
    "\n",
    "# QuadraticDiscriminantAnalysis\n",
    "classifier = QuadraticDiscriminantAnalysis()\n",
    "\n",
    "\n",
    "#TRAIN MODEL\n",
    "classifier.fit(X_train, y_train)  # Train the classifier\n",
    "\n",
    "\n",
    "\n",
    "# TASK: PREDICT NEW VALUES\n",
    "# Predict y data with classifier: \n",
    "y_predict = classifier.predict(X_test)\n",
    "\n",
    "#TASK: EVALUATE RESULTS\n",
    "# Print results: \n",
    "print(confusion_matrix(y_test, y_predict))\n",
    "print(classification_report(y_test, y_predict)) \n",
    "\n",
    "# Evaluate label (subsets) accuracy\n",
    "print(accuracy_score(y_test, y_predict))\n",
    "\n",
    "print(y_test, y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4d3f636",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tip for modularization\n",
    "https://scikit-learn.org/stable/auto_examples/classification/plot_classifier_comparison.html#sphx-glr-auto-examples-classification-plot-classifier-comparison-py\n",
    "\n",
    "\n",
    "\n",
    "#https://towardsdatascience.com/machine-learning-with-python-classification-complete-tutorial-d2c99dc524ec"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
