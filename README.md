#CS3091 Final Submission## Des This program is meant to compile data from various observatories,read it into one dataframe, engineer variables, and optimize machine learningmodels to fit the data. The process for running the grid search is quite computationally heavy,so we run the search and store the trained model as a joblib file.## Architecture### Reading data - data_reader.py    Standardizing Labels / Features    Combine data from diffferent regions    Ourputs a full csv of X and Y dat    ### Explatory Data Analysis    ### data enginnering - data_edit.py    >>>>>>    ### Model Selection    >>>>>## ResultsRunning the grid search resultes in the following parameters:[omplementNB(alpha=2), Perceptron(alpha=1e-09, n_iter_no_change=15, penalty='l1'),  SVC(C=0.75, degree=2, kernel='poly'),  SGDClassifier(eta0=0.0001, penalty='l1', shuffle=False),  PassiveAggressiveClassifier(C=0.25, class_weight='balanced'),  LinearDiscriminantAnalysis(shrinkage='auto', solver='lsqr'),  QuadraticDiscriminantAnalysis(reg_param=0.5),  KNeighborsClassifier(algorithm='ball_tree', leaf_size=10, n_neighbors=20, p=1,                      weights='distance'),                       DecisionTreeClassifier(max_depth=10, min_samples_leaf=2,                        min_weight_fraction_leaf=0)                                                                        ## EVALUATIONThe best model was a Support Vector Machine with about 90% accuracy.                                                                                                                         Running evaluate() in model_finder.py givesSummary of dataframe scaled with QuantileTransformer():<bound method NDFrame.describe of             0         1         2   ...        45        46        470     0.990606  0.991915  0.997417  ...  0.249750  0.506507  1.0000001     0.995162  0.996449  0.999320  ...  0.249750  0.364748  1.0000002     0.985459  0.784785  0.858609  ...  0.420420  0.682865  0.7392393     0.976962  0.986150  0.995266  ...  0.475475  0.576005  1.0000004     0.950089  0.963964  0.990869  ...  0.249750  0.840841  1.000000       ...       ...       ...  ...       ...       ...       ...5102  0.621622  0.126126  0.106607  ...  0.113614  0.050551  0.3428435103  0.255756  0.621622  0.656657  ...  0.776276  0.750751  0.7392395104  0.255756  0.461061  0.519520  ...  0.949449  0.323824  0.7392395105  0.896897  0.211211  0.171171  ...  0.794795  0.725225  0.7392395106  0.744745  0.282407  0.213714  ...  0.856356  0.482482  0.739239[5107 rows x 48 columns]>Shape of original Dataframe: (5107, 48) (5107,)     Shape of training data: (3574, 48) (3574,)     Shape of testing data: (1533, 48) (1533,)Confusion Matrix and full Classification Report of NB: [[743 108  11] [220 370   1] [  6  62  12]]              precision    recall  f1-score   support           1       0.77      0.86      0.81       862           2       0.69      0.63      0.65       591           3       0.50      0.15      0.23        80    accuracy                           0.73      1533   macro avg       0.65      0.55      0.57      1533weighted avg       0.72      0.73      0.72      1533Overall Accuracy of NB: 0.7338551859099804Confusion Matrix and full Classification Report of Perceptron: [[796  64   2] [106 482   3] [  3  15  62]]              precision    recall  f1-score   support           1       0.88      0.92      0.90       862           2       0.86      0.82      0.84       591           3       0.93      0.78      0.84        80    accuracy                           0.87      1533   macro avg       0.89      0.84      0.86      1533weighted avg       0.87      0.87      0.87      1533Overall Accuracy of Perceptron: 0.8741030658838878Confusion Matrix and full Classification Report of SVM: [[804  54   4] [106 484   1] [  3   7  70]]              precision    recall  f1-score   support           1       0.88      0.93      0.91       862           2       0.89      0.82      0.85       591           3       0.93      0.88      0.90        80    accuracy                           0.89      1533   macro avg       0.90      0.88      0.89      1533weighted avg       0.89      0.89      0.89      1533Overall Accuracy of SVM: 0.8858447488584474Confusion Matrix and full Classification Report of SGD: [[798  64   0] [102 484   5] [  6  16  58]]              precision    recall  f1-score   support           1       0.88      0.93      0.90       862           2       0.86      0.82      0.84       591           3       0.92      0.72      0.81        80    accuracy                           0.87      1533   macro avg       0.89      0.82      0.85      1533weighted avg       0.87      0.87      0.87      1533Overall Accuracy of SGD: 0.8741030658838878Confusion Matrix and full Classification Report of PassiveAggressive: [[797  62   3] [113 474   4] [  4  17  59]]              precision    recall  f1-score   support           1       0.87      0.92      0.90       862           2       0.86      0.80      0.83       591           3       0.89      0.74      0.81        80    accuracy                           0.87      1533   macro avg       0.87      0.82      0.84      1533weighted avg       0.87      0.87      0.87      1533Overall Accuracy of PassiveAggressive: 0.867579908675799Confusion Matrix and full Classification Report of LinearDisc: [[805  56   1] [473 113   5] [ 30  16  34]]              precision    recall  f1-score   support           1       0.62      0.93      0.74       862           2       0.61      0.19      0.29       591           3       0.85      0.42      0.57        80    accuracy                           0.62      1533   macro avg       0.69      0.52      0.53      1533weighted avg       0.63      0.62      0.56      1533Overall Accuracy of LinearDisc: 0.6210045662100456Confusion Matrix and full Classification Report of QuadDisc: [[821  39   2] [249 329  13] [  9  10  61]]              precision    recall  f1-score   support           1       0.76      0.95      0.85       862           2       0.87      0.56      0.68       591           3       0.80      0.76      0.78        80    accuracy                           0.79      1533   macro avg       0.81      0.76      0.77      1533weighted avg       0.81      0.79      0.78      1533Overall Accuracy of QuadDisc: 0.7899543378995434Confusion Matrix and full Classification Report of KNN: [[784  78   0] [132 454   5] [  2  10  68]]              precision    recall  f1-score   support           1       0.85      0.91      0.88       862           2       0.84      0.77      0.80       591           3       0.93      0.85      0.89        80    accuracy                           0.85      1533   macro avg       0.87      0.84      0.86      1533weighted avg       0.85      0.85      0.85      1533Overall Accuracy of KNN: 0.8519243313763861Confusion Matrix and full Classification Report of DeciscionTree: [[779  80   3] [121 469   1] [  3  12  65]]              precision    recall  f1-score   support           1       0.86      0.90      0.88       862           2       0.84      0.79      0.81       591           3       0.94      0.81      0.87        80    accuracy                           0.86      1533   macro avg       0.88      0.84      0.86      1533weighted avg       0.86      0.86      0.86      1533Overall Accuracy of DeciscionTree: 0.8564905414220483